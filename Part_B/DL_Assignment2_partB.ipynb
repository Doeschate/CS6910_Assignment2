{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WQdnTR0FOP"
      },
      "outputs": [],
      "source": [
        "import sys,os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets,models\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from PIL import Image as image1\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#conv2d(input_channels, output_channels, kernel_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsCIYkhc0Gum"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9UGwcqe0LTt"
      },
      "outputs": [],
      "source": [
        "# Data compression\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "ghghgh\n",
        "trainingData = []\n",
        "trainingLabels = []\n",
        "\n",
        "#folders = ['Animalia', 'Aves', 'Amphibia', 'Arachnida', 'Plantae', 'Fungi', 'Mollusca', 'Mammalia', 'Insecta', 'Reptilia']\n",
        "folders = ['Mammalia', 'Insecta']\n",
        "classes = { folders[i] : i for i in range(0,len(folders))}\n",
        "#folders = folders[:3]\n",
        "\n",
        "resize = T.Compose([\n",
        "    T.ToPILImage(),           \n",
        "    T.Resize(224)])\n",
        "\n",
        "for name in folders:\n",
        "  print(name)\n",
        "  start_time = datetime.now()\n",
        "  imdir = '/content/drive/MyDrive/nature_12K/inaturalist_12K/train/'+name+'/'\n",
        "  ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
        "\n",
        "  files = []\n",
        "  [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
        "\n",
        "  images = [cv2.imread(file) for file in files]\n",
        "  \n",
        "  count=1\n",
        "  for img in images:\n",
        "    rimg = resize(img)\n",
        "    rimg.save('/content/drive/MyDrive/nature_12K/resized/train/'+name+'/'+str(count)+'.jpg')\n",
        "    count+=1\n",
        "\n",
        "  end_time = datetime.now()\n",
        "  print('Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "print(\"=========== Testing =====================\")\n",
        "testingData = []\n",
        "testingLabels = []\n",
        "for name in folders:\n",
        "  print(name)\n",
        "  start_time = datetime.now()\n",
        "  imdir = '/content/drive/MyDrive/nature_12K/inaturalist_12K/val/'+name+'/'\n",
        "  ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
        "\n",
        "  files = []\n",
        "  [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
        "\n",
        "  testingData = [cv2.imread(file) for file in files]\n",
        "\n",
        "  count=1\n",
        "  for img in testingData:\n",
        "    rimg = resize(img)\n",
        "    rimg.save('/content/drive/MyDrive/nature_12K/resized/test/'+name+'/'+str(count)+'.jpg')\n",
        "    count+=1\n",
        "\n",
        "  \n",
        "  end_time = datetime.now()\n",
        "  print('Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "trainingData = np.array(trainingData)\n",
        "testingData  = np.array(testingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjKVxlXD0NEF"
      },
      "outputs": [],
      "source": [
        "# Data Loading\n",
        "\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "trainingData = []\n",
        "trainingLabels = []\n",
        "validationData = []\n",
        "validationLabels = []\n",
        "\n",
        "folders = ['Animalia', 'Aves', 'Amphibia', 'Arachnida', 'Plantae', 'Fungi', 'Mollusca', 'Mammalia', 'Insecta', 'Reptilia']\n",
        "classes = { folders[i] : i for i in range(0,len(folders))}\n",
        "\n",
        "print(\"=========== Training Images=====================\")\n",
        "for name in folders:\n",
        "  print(name)\n",
        "  start_time = datetime.now()\n",
        "  imdir = '/content/drive/MyDrive/nature_12K/resized/train/'+name+'/'\n",
        "  ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
        "\n",
        "  files = []\n",
        "  [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
        "\n",
        "  tempTrainingImages = [cv2.imread(file) for file in files]\n",
        "  tempTrainingLabels = [classes[name] for i in range(0,len(files))]\n",
        "\n",
        "  tempTrainingImages = np.array(tempTrainingImages,dtype=object)\n",
        "  tempTrainingLabels = np.array(tempTrainingLabels)\n",
        "  \n",
        "\n",
        "  x_train, x_val, y_train, y_val = train_test_split(tempTrainingImages, tempTrainingLabels, test_size=0.1, random_state=33)\n",
        "\n",
        "  trainingData = trainingData + list(x_train)\n",
        "  trainingLabels = trainingLabels + list(y_train)\n",
        "\n",
        "  validationData = validationData + list(x_val)\n",
        "  validationLabels = validationLabels + list(y_val)\n",
        "  \n",
        "  end_time = datetime.now()\n",
        "  print('-> Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "\n",
        "print(\"=========== Testing Images=====================\")\n",
        "testingData = []\n",
        "testingLabels = []\n",
        "for name in folders:\n",
        "  print(name)\n",
        "  start_time = datetime.now()\n",
        "  imdir = '/content/drive/MyDrive/nature_12K/resized/test/'+name+'/'\n",
        "  ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
        "\n",
        "  files = []\n",
        "  [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
        "\n",
        "  testingData = testingData + [cv2.imread(file) for file in files]\n",
        "  testingLabels = testingLabels + [classes[name] for i in range(0,len(files))]\n",
        "\n",
        "  end_time = datetime.now()\n",
        "  print('-> Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "trainingData = np.array(trainingData,dtype=object)\n",
        "validationData = np.array(validationData,dtype=object)\n",
        "testingData  = np.array(testingData,dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create dictionary for class indexes\n",
        "train_data_path = os.path.join(actual_data_path, \"train\")\n",
        "classes = [] #to store class values\n",
        "for data_path in glob.glob(train_data_path + \"/*\"):\n",
        "    classes.append(data_path.split('/')[-1])\n",
        "idx_to_class = {i:j for i, j in enumerate(classes)} #index to class map\n",
        "class_to_idx = {value:key for key,value in idx_to_class.items()} #class to index map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking if gpu is available or not\n",
        "Device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(Device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get all the paths from train_data_path and returns image paths for train and validation set\n",
        "def CreateTrainDataset(actual_data_path):\n",
        "    train_data_path = os.path.join(actual_data_path, \"train\")\n",
        "    train_image_paths = [] #to store image paths in list\n",
        "    classes = [] #to store class values\n",
        "    for data_path in glob.glob(train_data_path + \"/*\"):\n",
        "        train_image_paths.append(glob.glob(data_path + '/*')) #stores all the training image paths in this list\n",
        "    train_image_paths = list(chain.from_iterable(train_image_paths))\n",
        "    random.shuffle(train_image_paths)\n",
        "\n",
        "    # split train valid from train paths (90,10)\n",
        "    train_image_paths, valid_image_paths = train_image_paths[:int(0.9*len(train_image_paths))], train_image_paths[int(0.9*len(train_image_paths)):] \n",
        "    return train_image_paths, valid_image_paths\n",
        "\n",
        "# create the test_image_paths\n",
        "def CreateTestDataset(actual_data_path):\n",
        "    test_data_path = os.path.join(actual_data_path, \"val\")\n",
        "    test_image_paths = []\n",
        "    for data_path in glob.glob(test_data_path + '/*'):\n",
        "        test_image_paths.append(glob.glob(data_path + '/*')) #stores all the test images path in this list\n",
        "    test_image_paths = list(chain.from_iterable(test_image_paths))\n",
        "    return test_image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function returns images and corresponding lebels after performing transforms\n",
        "class iNaturalist_12KDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        label = image_filepath.split('/')[-2]\n",
        "        label = class_to_idx[label]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        return image, label\n",
        "    \n",
        "# all input images are resized reshized_shape   \n",
        "resized_shape = 256\n",
        "\n",
        "# Data augumentation transform functions\n",
        "augmented_transforms = A.Compose([A.SmallestMaxSize(max_size=350),\n",
        "              A.Resize(resized_shape,resized_shape),\n",
        "              A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
        "              A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "              A.RandomBrightnessContrast(p=0.5),\n",
        "              A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),\n",
        "              A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "              A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "              A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "              ToTensorV2()])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "DL_Assignment2_partB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
